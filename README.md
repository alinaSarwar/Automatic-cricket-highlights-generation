# Automatic-cricket-highlights-generation

Cricket is the second most watched sports game in the world. It has a complex set of rules and is played for a longer duration than most other sports. Even the shortest format of cricket, T20, has a 3-3.5 hours long match, on average. It is no surprise that a lot of people, despite being cricket lovers, are unable to keep up with the live matches because of their busy work schedules. Most people are only able to catch fleeting finishes to the matches. Also, once the result of the game is out and people already know who eventually won the game, there is much less motivation left to watch the whole package. Rather, people prefer watching highlights of the game, which includes just the most interesting events of the game. Producing sports highlights manually, especially those of cricket, is a time-consuming and cumbersome task. An efficient method to generate these highlights automatically would not only save manpower but also make sure that the highlights become available for the viewers to watch soon after the match ends. 

In this project, we aim to implement an approach introduced in a recent [paper](https://www.ijitee.org/wp-content/uploads/papers/v8i11/J11180881019.pdf) by Agarwal et al  for automatically generating cricket highlights. The proposed method reformulates the problem of generating cricket highlights as simply annotating each and every ball of the game in terms of whether an important event (eg. a four, a six, a fall of wicket etc) occurred during that ball. It works by segmenting a full match video into individual ball clips using a self-trained Convolutional Neural Network (CNN) to detect the start of the ball and Optical Character Recognition (OCR) for detecting the changes in the scorecard and signaling the end of that ball. Once every ball has been tagged as “interesting” enough or not, the process of generating highlights is then as simple as stitching all such relevant ball clips together into a highlights package.
